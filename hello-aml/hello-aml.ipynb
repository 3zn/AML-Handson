{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure MLで学習済みモデルの作成からデプロイまで\n",
    "\n",
    "このチュートリアルでは、`Azure Machine Learning（Azure ML）Python SDK`を使用して、  \n",
    "モデルのトレーニング、ハイパーパラメーターの調整、およびデプロイを行います。  \n",
    "※ディープラーニングのフレームワークには`PyTorch`を使用します。  \n",
    "\n",
    "\n",
    "問題設定は[Transfer Learningチュートリアル](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)から、  Transfer Learning（転移学習）を使用してアリとハチの画像分類になります。  \n",
    "\n",
    "*転移学習とは？*  \n",
    "転移学習とは学習済みモデルを使用して（ネットワークの構造と重みの再利用）、学習を行うことをさします。  \n",
    "類似のものとしてファインチューニングがありますが、学習済みモデルのネットワークの学習を行うのがファインチューニングになります。  \n",
    "転移学習では学習済みモデルのネットワーク自体の学習は行いません。（出力前の全結合層のみを学習させるのが一般的）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境構築\n",
    "\n",
    "環境は「[Azure Machine Learning Services](https://docs.microsoft.com/ja-jp/azure/machine-learning/service/) ワークスペース」にある`Azure Notebooks`を使用します。  \n",
    "Pythonの実行環境や、Azure ML Servicesを使用に必要な[Azure ML Python SDK](https://docs.microsoft.com/ja-jp/python/api/overview/azure/ml/intro?view=azure-ml-py)は既にインストールされています。　  \n",
    "\n",
    "では、まずは[Azure Portal](https://azure.microsoft.com/ja-jp/features/azure-portal/)を開いて、`Azure Notebooks`の準備を行いましょう。  \n",
    "今回は解説しませんがローカル環境で行う際には[こちらの公式ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/service/quickstart-create-workspace-with-python)を参照してください。  \n",
    "\n",
    "\n",
    "### リソースの作成\n",
    "\n",
    "まずは作業を行うためにAzure Machine Learning Services ワークスペースのリソースを作成します。  \n",
    "作成方法は[こちらの公式ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/service/quickstart-get-started)を確認してください。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バージョンの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.8\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AzrueML上では既にAzureML Python SDKが準備されているため、インストールする必要はありません。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ワークスペースの初期化\n",
    "\n",
    "[ワークスペース](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace)の初期化を行います。  \n",
    "`Workspace.from_config()`は`config.json`ファイルを参照してワークスペースを初期化します。  \n",
    "\n",
    "#### configファイルの編集\n",
    "\n",
    "`config.json`ファイルは基本的に自動でこのように設定を反映されます。  \n",
    "自身で設定する際には下記のように編集します。  \n",
    "\n",
    "```json\n",
    "\n",
    "{\n",
    "    \"subscription_id\": \"サブスクリプションID\",\n",
    "    \"resource_group\": \"リソースグループ名\",\n",
    "    \"workspace_name\": \"ワークスペース名\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "上記の情報はAzure Portalの画面から確認することができます。  \n",
    "では、実行して、ワークスペースの初期化を行います。  \n",
    "\n",
    "初期化を行う時に、サインインを要求されるので、表示されるコードをコピーして、URLをクリックします。  \n",
    "遷移先の画面でコピーしたコードを入力することによって、サインインが完了します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/nbuser/library/config.json\n",
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FK8RRVKBH to authenticate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Workspace name: dllab-azureml\n",
      "Azure region: eastus\n",
      "Resource group: dllab_azureml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンピューティング ターゲットの設定\n",
    "\n",
    "[コンピューティングターゲット](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target)を作成する必要があります。このチュートリアルではAzure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute))を使用します。  \n",
    "（コンピューティングターゲットは計算を実行する場所を決定するようなイメージです。）\n",
    "\n",
    "※AmlComputeの作成には約5分かかります。  \n",
    "その名前のAmlComputeが既にワークスペースにある場合、このコードは作成プロセスをスキップします。\n",
    "\n",
    "\n",
    "他のAzureサービスと同様に、Azure Machine Learningサービスに関連する特定のリソース（AmlComputeなど）には制限があります。  \n",
    "デフォルトの制限と、より多くのクォータを要求する方法についての[この記事](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas)を読んでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-01-28T10:06:04.204000+00:00', 'creationTime': '2019-01-28T10:04:39.638971+00:00', 'currentNodeCount': 0, 'errors': None, 'modifiedTime': '2019-01-28T10:06:08.656582+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 0, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4, vm_priority='dedicated')\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコードはGPUクラスターを作成します。  \n",
    "コードの中身を確認します。  \n",
    "`AmlCompute.provisioning_configuration()`でコンピューティング ターゲットの設定を行うことができます。  \n",
    "詳細は[こちらの公式ドキュメント](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.amlcompute(class)?view=azure-ml-py)を確認してください。  \n",
    "\n",
    "\n",
    "### 仮想マシンのサイズの変更\n",
    "\n",
    "代わりにCPUクラスタを作成したい場合は、 `STANDARD_D2_V2`のように` vm_size`パラメータに異なるVMサイズを指定してください。  \n",
    "\n",
    "CPUのVMサイズは[こちらの公式ドキュメント](https://docs.microsoft.com/ja-jp/azure/virtual-machines/linux/sizes-general)を確認してください。  \n",
    "GPUのVMサイズは[こちらの公式ドキュメント](https://docs.microsoft.com/ja-jp/azure/virtual-machines/linux/sizes-gpu)を確認してください。  \n",
    "\n",
    "今回はNVIDIAのTesla K80が1枚の仮想マシン`STANDARD_NC6`を使用します。  \n",
    "計算リソースを増やすためにはNCの他のシリーズを使用するもしくはGPUの枚数を増やすことによって行うことが可能です。  \n",
    "\n",
    "\n",
    "### 仮想マシンの割り当ての設定\n",
    "\n",
    "Azureの仮想マシンのプライオリティ（優先度）を選択することができます。  \n",
    "選択肢は`dedicated`または`lowpriority`の２つから選択することができます。  \n",
    "（デフォルトでは`dedicated`が選択されています。）  \n",
    "\n",
    "dedicatedは問題なく仮想マシンが割り当てられますが、lowpriorityは価格が安い代わりに割り込みが入る可能性などいくつかデメリットがあります。  \n",
    "しかし、価格が約8割ほど安くなるのは大きなメリットです。  \n",
    "\n",
    "\n",
    "### クラスターのノード数の設定\n",
    "\n",
    "`max_nodes`でコンピューティングでジョブを実行中に自動スケールアップする最大ノード数を指定することが可能です。  \n",
    "ノード数はVMの数を表すため最大数が増えると計算リソースが増えますが、同時に発生する料金も増えます。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUクラスタを使用しての学習の実行\n",
    "\n",
    "リモートコンピューティングクラスタを使用して学習する準備が整いました。  \n",
    "Pytorchでの学習のスクリプトと学習用のデータを準備します。  \n",
    "\n",
    "今回は事前に準備されたものを使用します。　　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクトディレクトリの作成\n",
    "\n",
    "学習実行に必要なコードを格納するディレクトリを作成します。  \n",
    "このディレクトリには学習を実行するコードと、それに依存関係のファイルなどを格納するする必要があります。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './pytorch-hymenoptera'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は`pytorch-hymenoptera`という名前のプロジェクトフォルダを作成しました。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "\n",
    "今回は[こちら](https://download.pytorch.org/tutorial/hymenoptera_data.zip)のデータセットを使用します。  \n",
    "（ダウンロードの必要はありません）\n",
    "\n",
    "\n",
    "こちらにはアリとミツバチの画像それぞれ約120個ずつの訓練データ、75個の検証データが含まれています。  \n",
    "学習用のスクリプトである`pytorch_train.py`内にデータセットをダウンロードして取得するコードがあるため、  \n",
    "こちらのデータは今回はダウンロードして準備する必要はありません。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用スクリプトの準備\n",
    "\n",
    "学習用のスクリプトは用意されている`pytorch_train.py`を使用します。  \n",
    "\n",
    "\n",
    "### スクリプトの確認\n",
    "\n",
    "今回使用するスクリプトはこちらになります。  \n",
    "\n",
    "`pytorch_train.py`  \n",
    "\n",
    "```python\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "from azureml.core.run import Run\n",
    "# get the Azure ML run object\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Load the train/val data.\"\"\"\n",
    "\n",
    "    # Data augmentation and normalization for training\n",
    "    # Just normalization for validation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                              data_transforms[x])\n",
    "                      for x in ['train', 'val']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                                  shuffle=True, num_workers=4)\n",
    "                   for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    return dataloaders, dataset_sizes, class_names\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, data_dir):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "\n",
    "    # load training/validation data\n",
    "    dataloaders, dataset_sizes, class_names = load_data(data_dir)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # log the best val accuracy to AML run\n",
    "            run.log('best_val_acc', np.float(best_acc))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "def fine_tune_model(num_epochs, data_dir, learning_rate, momentum):\n",
    "    \"\"\"Load a pretrained model and reset the final fully connected layer.\"\"\"\n",
    "\n",
    "    # log the hyperparameter metrics to the AML run\n",
    "    run.log('lr', np.float(learning_rate))\n",
    "    run.log('momentum', np.float(momentum))\n",
    "\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)  # only 2 classes to predict\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(),\n",
    "                             lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(\n",
    "        optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "    model = train_model(model_ft, criterion, optimizer_ft,\n",
    "                        exp_lr_scheduler, num_epochs, data_dir)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def download_data():\n",
    "    \"\"\"Download and extract the training data.\"\"\"\n",
    "    import urllib\n",
    "    from zipfile import ZipFile\n",
    "    # download data\n",
    "    data_file = './hymenoptera_data.zip'\n",
    "    download_url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "    urllib.request.urlretrieve(download_url, filename=data_file)\n",
    "\n",
    "    # extract files\n",
    "    with ZipFile(data_file, 'r') as zip:\n",
    "        print('extracting files...')\n",
    "        zip.extractall()\n",
    "        print('finished extracting')\n",
    "        data_dir = zip.namelist()[0]\n",
    "\n",
    "    # delete zip file\n",
    "    os.remove(data_file)\n",
    "    return data_dir\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "    # get command-line arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--num_epochs', type=int, default=25,\n",
    "                        help='number of epochs to train')\n",
    "    parser.add_argument('--output_dir', type=str, help='output directory')\n",
    "    parser.add_argument('--learning_rate', type=float,\n",
    "                        default=0.001, help='learning rate')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    data_dir = download_data()\n",
    "    print(\"data directory is: \" + data_dir)\n",
    "    model = fine_tune_model(args.num_epochs, data_dir,\n",
    "                            args.learning_rate, args.momentum)\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    torch.save(model, os.path.join(args.output_dir, 'model.pt'))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "こちらのスクリプトの詳細の説明は行いませんが、実行内容としては下記の4ステップになります。    \n",
    "\n",
    "1. データのダウンロード\n",
    "2. 必要な前処理の適応\n",
    "3. 学習の実行\n",
    "4. 結果の取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure MLの学習結果をログに保存\n",
    "\n",
    "上記のコードにはAzure MLの環境で学習を実行し、結果を追跡するにはいくつかのAzure MLコードが追記されています。  \n",
    "詳細は[こちらの公式のドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/service/how-to-track-experiments)を確認してください。  \n",
    "今回記述されている内容をそれぞれ確認しましょう。  \n",
    "\n",
    "学習経過には`Azure ML Run`オブジェクトを使用することによってアクセスすることができます。    \n",
    "上記のコード内で設定を行なっている部分を確認しましょう。  \n",
    "\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "\n",
    "さらに`learning rate`、`momentum`のパラメータ、検証データに対する最高のAccuracy（正解率）のログも取得します。  \n",
    "\n",
    "```Python\n",
    "run.log('lr', np.float(learning_rate))\n",
    "run.log('momentum', np.float(momentum))\n",
    "\n",
    "run.log('best_val_acc', np.float(best_acc))\n",
    "```\n",
    "\n",
    "ハイパーパラメータの調整を行う際にこちらのログは重要な役割を果たします。  \n",
    "こちらのスクリプトを先ほど作成した、作業ディレクトリに保存しておきます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pytorch-hymenoptera/pytorch_train.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('pytorch_train.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentの作成\n",
    "ワークスペースですべての実行結果を追跡するために[Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) を作成します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-hymenoptera'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch estimatorの作成\n",
    "\n",
    "Azure ML SDKのPyTorch estimatorを使用すると、単一ノードと分散の両方の実行について、PyTorchトレーニングジョブを簡単に送信できます。   \n",
    "PyTorch estimatorの詳細については、[こちら](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch)を参照してください。次のコードは単一ノードのPyTorchジョブを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--num_epochs': 30,\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='pytorch_train.py',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scripti_params`に訓練に必要な引数を渡す必要があります。　　\n",
    "\n",
    "\n",
    "#### script_params\n",
    "\n",
    "`script_params`は` entry_script`で指定しているスクリプトに必要な引数を渡す辞書型のオブジェクトです。  \n",
    "今回の設定は下記になります。  \n",
    "- `--num_epochs`:`30`→エポック数を30に設定\n",
    "- `'--output_dir': './outputs'`→学習の実行履歴を保存するディレクトリの指定\n",
    "\n",
    "この出力ディレクトリである `./ output`はAzure ML上で特別に扱われます。  \n",
    "このディレクトリ内の情報は全て実行履歴の一部としてワークスペースにアップロードされ、リモート実行が終了してもアクセス可能です。\n",
    "\n",
    "#### データストアからデータの読み込み\n",
    "\n",
    "訓練時にデータを読み込む必要がある場合はデータストアと呼ばれる場所にデータをUploadし、そこからデータを読み込む必要があります。  \n",
    "その方法については[こちらの公式ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/service/how-to-access-data)を確認してください。  \n",
    "（データストアはワークスペースのリソースを作成した段階で使用可能になります。）  \n",
    "\n",
    "\n",
    "#### GPUの使用\n",
    "\n",
    "Azure VMのGPUをトレーニングに活用するには、`use_gpu = True`に設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ジョブの実行\n",
    "\n",
    "Estimatorオブジェクトを送信してExperimentを実行します。  \n",
    "この実行は非同期です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: pytorch-hymenoptera,\n",
      "Id: pytorch-hymenoptera_1548675415501,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'pytorch-hymenoptera_1548675415501', 'target': 'gpucluster', 'status': 'Queued', 'properties': {'azureml.runsource': 'experiment', 'ContentSnapshotId': 'ee1c7a9d-7148-477d-90f3-cbbfe520088a'}, 'runDefinition': {'Script': 'pytorch_train.py', 'Arguments': ['--num_epochs', '30', '--output_dir', './outputs'], 'SourceDirectoryDataStore': None, 'Framework': 0, 'Communicator': 0, 'Target': 'gpucluster', 'DataReferences': {}, 'JobName': None, 'AutoPrepareEnvironment': True, 'MaxRunDurationSeconds': None, 'NodeCount': 1, 'Environment': {'Python': {'InterpreterPath': 'python', 'UserManagedDependencies': False, 'CondaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'torch==1.0.0', 'torchvision==0.2.1']}]}}, 'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'NCCL_SOCKET_IFNAME': '^docker0'}, 'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1', 'Enabled': True, 'SharedVolumes': True, 'Preparation': None, 'GpuSupport': True, 'ShmSize': '1g', 'Arguments': [], 'BaseImageRegistry': {'Address': None, 'Username': None, 'Password': None}}, 'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'], 'Packages': [{'Group': 'com.microsoft.ml.spark', 'Artifact': 'mmlspark_2.11', 'Version': '0.12'}], 'PrecachePackages': True}}, 'History': {'OutputCollection': True}, 'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'BatchAi': {'NodeCount': 0}, 'AmlCompute': {'Name': None, 'VmSize': None, 'VmPriority': None, 'RetainCluster': False, 'ClusterMaxNodeCount': 1}, 'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1}, 'Mpi': {'ProcessCountPerNode': 1}, 'Hdi': {'YarnDeployMode': 2}, 'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0}, 'ExposedPorts': None, 'PrepareEnvironment': None}, 'logFiles': {}}\n"
     ]
    }
   ],
   "source": [
    "# to get more details of your run\n",
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行経過の確認\n",
    "\n",
    "Jupyter Notebookのウィジェットを使用して実行の進行状況を監視できます。  \n",
    "実行依頼と同様に、ウィジェットは非同期で、ジョブが完了するまで10〜15秒ごとにライブアップデートを行います。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27aa2d859f0c4dd7ae1dfee074754a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、スクリプトがトレーニングを完了するまでブロックしてから、学習結果を確認することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-hymenoptera_1548675415501\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-hymenoptera_1548675415501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'pytorch-hymenoptera_1548675415501',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-01-28T11:41:54.927543Z',\n",
       " 'endTimeUtc': '2019-01-28T11:54:18.579572Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'ee1c7a9d-7148-477d-90f3-cbbfe520088a'},\n",
       " 'runDefinition': {'Script': 'pytorch_train.py',\n",
       "  'Arguments': ['--num_epochs', '30', '--output_dir', './outputs'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'gpucluster',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults', 'torch==1.0.0', 'torchvision==0.2.1']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://dllabazureml5427306140.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-hymenoptera_1548675415501/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=A8YxZGBACIWAJ4YnM0uyy45cuTakXNcEULYkLQ6MxRk%3D&st=2019-01-28T11%3A45%3A50Z&se=2019-01-28T19%3A55%3A50Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://dllabazureml5427306140.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-hymenoptera_1548675415501/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=FuOM6Gk91EIbUumaYqliPP78ZEaqGqeCno3N2BIF8Mw%3D&st=2019-01-28T11%3A45%3A50Z&se=2019-01-28T19%3A55%3A50Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://dllabazureml5427306140.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-hymenoptera_1548675415501/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=JOuG4y0OxLCK2mE9kp1qwTrc3p9IkRVuqitee0KsUEU%3D&st=2019-01-28T11%3A45%3A50Z&se=2019-01-28T19%3A55%3A50Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://dllabazureml5427306140.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-hymenoptera_1548675415501/azureml-logs/55_batchai_execution.txt?sv=2018-03-28&sr=b&sig=IL3%2FVaufLHdIqlVrJ4rXVWkTxPRWkYa6VAjYon3cVzA%3D&st=2019-01-28T11%3A45%3A50Z&se=2019-01-28T19%3A55%3A50Z&sp=r'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルのデプロイ\n",
    "\n",
    "学習済みモデルが作成できました。  \n",
    "続いてそのモデルをAzureにデプロイします。   \n",
    "今回はモデルを[Azure Container Instances](https://docs.microsoft.com/en-us/azure/container-instances/)（ACI）にWebサービスとしてデプロイします。   \n",
    "Azure MLを使用してモデルを展開する方法の詳細については、[こちら](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルの保存\n",
    "\n",
    "`run.register_model`を使用すると学習済みモデルを保存することが可能です。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-hymenoptera\tpytorch-hymenoptera:1\t1\n"
     ]
    }
   ],
   "source": [
    "model = run.register_model(model_name='pytorch-hymenoptera', model_path='outputs/model.pt')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スコアリングスクリプトの作成\n",
    "\n",
    "まず、Webサービスに呼び出されるスコアリングスクリプトを作成します。  \n",
    "スコアリングスクリプトには、2つの関数が必要になります。\n",
    "\n",
    "- `init（）`：この関数では、通常モデルを `global`オブジェクトにロードします。この関数はDockerコンテナが起動されたときに一度だけ実行されます。\n",
    "- `run（input_data）`：この関数では、新たな入力データ対して学習済みモデルを使用して推論を実行します。通常は入力と出力は通常シリアライゼーションとデシリアライゼーションのフォーマットとしてJSONを使用しますが、他のフォーマットも使用することが可能です。\n",
    "\n",
    "今回は準備されている`pytorch_score.py`を使用します。  \n",
    "また用意されているテスト用の画像ファイルを使用して推論を実行します。  \n",
    "独自のスコアリングスクリプトを書くときは、Webサービスを実行する前にまずローカルでテストすることを忘れないでください。  \n",
    "\n",
    "使用するスクリプトは下記になります。  \n",
    "\n",
    "```python\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('pytorch-hymenoptera')\n",
    "    model = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    input_data = torch.tensor(json.loads(input_data)['data'])\n",
    "\n",
    "    # get prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "        classes = ['ants', 'bees']\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        pred_probs = softmax(output).numpy()[0]\n",
    "        index = torch.argmax(output, 1)\n",
    "\n",
    "    result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n",
    "    return result\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境ファイルを作成する\n",
    "\n",
    "スコアリングスクリプトのすべてのパッケージ依存関係を指定する環境ファイル（ `myenv.yml`）を作成する必要があります。このファイルは、Azure MLによってこれらのすべての依存関係がDockerイメージにインストールされるようにするために使用されます。この場合、 `azureml-core`、` torch`、そして `torchvision`が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults==1.0.8\n",
      "  - torch\n",
      "  - torchvision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=['azureml-defaults', 'torch', 'torchvision'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "print(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerイメージの設定\n",
    "\n",
    "ACIコンテナーを構築するために使用するDockerイメージを構成します。  \n",
    "詳細については[こちらの公式ドキュメント](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.image.containerimage?view=azure-ml-py)を確認してください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script='pytorch_score.py', \n",
    "                                                  runtime='python', \n",
    "                                                  conda_file='myenv.yml',\n",
    "                                                  description='Image with hymenoptera model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACIコンテナの設定\n",
    "\n",
    "デプロイのための準備がほぼ整いました。   \n",
    "ACIコンテナに必要なCPUの数とギガバイトのRAMを指定するためのデプロイメント構成ファイルを作成します。  \n",
    "それは作成したモデルに依存しますが、一般的なモデルではデフォルトの `1`コアと` 1`ギガバイトのRAMで十分なケースが多いです。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={'data': 'hymenoptera',  'method':'transfer learning', 'framework':'pytorch'},\n",
    "                                               description='Classify ants/bees using transfer learning with PyTorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container Instances にデプロイする\n",
    "\n",
    "最後に、登録したモデルからWebサービスをデプロイしましょう。  \n",
    "前の手順で作成したACI設定ファイルとイメージ設定ファイルを使用してWebサービスをデプロイします。  \n",
    "\n",
    "リストの中の `model`オブジェクトを` models`パラメータに渡します。  \n",
    "複数の登録済みモデルをデプロイする場合は、このリストに他のモデルを追加してください。　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Image creation operation finished for image aci-hymenoptera:2, operation \"Succeeded\"\n",
      "Creating service\n",
      "Running........................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 7.82 s, sys: 696 ms, total: 8.51 s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = 'aci-hymenoptera'\n",
    "service = Webservice.deploy_from_model(workspace=ws,\n",
    "                                       name=service_name,\n",
    "                                       models=[model],\n",
    "                                       image_config=image_config,\n",
    "                                       deployment_config=aciconfig,)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常デプロイには7~8分かかります。  \n",
    "下記のように表示されればデプロイが成功しています。  \n",
    "\n",
    "```\n",
    "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
    "\n",
    "```\n",
    "\n",
    "#### デプロイがうまくいかない場合\n",
    "\n",
    "もし、何らかの理由でデプロイが失敗して再デプロイする必要がある場合は、必ずサービスを`service.delete（）`で削除してください。  \n",
    "\n",
    "**また、デプロイに問題が発生した場合、まず下記のコマンドを実行して、サービスからログを取得しましょう。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESTクライアント呼び出しを受け付けるWebサービスのHTTPエンドポイントを取得します。  \n",
    "このエンドポイントは、Webサービスをテストしたい、またはそれをアプリケーションに統合したい人と共有することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://104.45.171.246:80/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デプロイされたサービスをテストする\n",
    "\n",
    "最後に、デプロイしたWebサービスをテストしましょう。  \n",
    "データをJSON文字列としてACIでホストされているWebサービスに送信し、SDKの `run` APIを使用してサービスを呼び出します。  \n",
    "ここで、検証データからイメージを取得して推論を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa5a4cd27f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(Image.open('test_img.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像データに対して学習時と同じ前処理を適応し、推論が実行できる状態に変更します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "    \n",
    "def preprocess(image_file):\n",
    "    \"\"\"Preprocess the input image.\"\"\"\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_file)\n",
    "    image = data_transforms(image).float()\n",
    "    image = torch.tensor(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デプロイしたAPIを使用して推論を実行します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'bees', 'probability': '0.999579'}\n"
     ]
    }
   ],
   "source": [
    "input_data = preprocess('test_img.jpg')\n",
    "result = service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "うまく推論ができていることが確認できました。  \n",
    "このデプロイされたモデルに関してはAzure Portalの「デプロイ」タブから詳細情報について確認することができます。  \n",
    "\n",
    "これでAzure Machine Learningの基礎的な使用方法が理解できました。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 後片付け\n",
    "\n",
    "Webサービスが不要になったら、API呼び出しで簡単に削除できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いては一緒に手持ちのデータを使用して学習を行う方法を確認します。  \n",
    "また今回は行わなかったハイパーパラメータの調整方法もご紹介します。  "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
